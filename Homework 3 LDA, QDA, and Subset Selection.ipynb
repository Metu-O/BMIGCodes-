{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading the auto data set and viewing its description\n",
    "input_file = \"Auto.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a binary variable(0,1), named mpg01, based on the median mpg\n",
    "median_mpg = df[\"mpg\"].median()\n",
    "df[\"mpg01\"] = (df[\"mpg\"] >= df[\"mpg\"].median()).astype(int)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the data graphically using boxplots to view any associations\n",
    "#box-plots shows that mpg01 is correlated with cylinder, displacement, and origin \n",
    "plt.figure(figsize=(2,2))\n",
    "c = sns.boxplot(x=df[\"mpg01\"], y=df[\"cylinder\"], palette=\"Blues\", width=0.1);\n",
    "plt.show(c)\n",
    "plt.figure(figsize=(2,2))\n",
    "d = sns.boxplot(x=df[\"mpg01\"], y=df[\"displacement\"], palette=\"Accent\", width=0.1);\n",
    "plt.show(d)\n",
    "plt.figure(figsize=(2,2))\n",
    "h = sns.boxplot(x=df[\"mpg01\"], y=df[\"horsepower\"], palette=\"Accent\", width=0.1);\n",
    "plt.show(h)\n",
    "plt.figure(figsize=(2,2))\n",
    "w = sns.boxplot(x=df[\"mpg01\"], y=df[\"weight\"], palette=\"coolwarm\", width=0.1);\n",
    "plt.show(w)\n",
    "plt.figure(figsize=(2,2))\n",
    "a = sns.boxplot(x=df[\"mpg01\"], y=df[\"accelaration\"], palette=\"Purples\", width=0.1);\n",
    "plt.show(a)\n",
    "plt.figure(figsize=(2,2))\n",
    "y = sns.boxplot(x=df[\"mpg01\"], y=df[\"year\"], palette=\"Reds\", width=0.1);\n",
    "plt.show(y)\n",
    "plt.figure(figsize=(2,2))\n",
    "o = sns.boxplot(x=df[\"mpg01\"], y=df[\"origin\"], palette=\"autumn\", width=0.1);\n",
    "plt.show(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring associations between mpg01 and other features. \n",
    "\n",
    "#this\n",
    "corr_matrix = df.corr()\n",
    "corr_matrix[\"mpg01\"].sort_values(ascending=False)\n",
    "\n",
    "#or this\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.heatmap(df.corr(),annot = True) \n",
    "\n",
    "#cylinder, displacement, horsepower, weight are codependent\n",
    "#and highly correlated with mpg/mpg01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating out the features\n",
    "features = ['mpg','cylinder','displacement','horsepower', 'weight', 'accelaration','year','origin']\n",
    "X = df.loc[:, features].values\n",
    "\n",
    "# Separating out the target\n",
    "y = df.loc[:,['mpg01']].values\n",
    "\n",
    "# Standardizing the features\n",
    "X = StandardScaler().fit_transform(X)\n",
    "df2 = pd.DataFrame(X, columns = features)\n",
    "target = pd.DataFrame(y, columns = ['mpg01'])\n",
    "print(df2)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and test set: 80% train, 20% test \n",
    "np.random.seed(56)\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "X_train_set, X_test_set = split_train_test(df2, 0.2)\n",
    "y_train_set, y_test_set = split_train_test(target, 0.2)\n",
    "print(len(X_train_set))\n",
    "print(len(X_test_set))\n",
    "X_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit data using only two variables that seem most associated with mpg01\n",
    "features2 = ['cylinder','displacement','horsepower', 'weight']\n",
    "\n",
    "#lda using sklearn\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_train_set = X_train_set [features2]\n",
    "y_train_set = y_train_set['mpg01']\n",
    "lda.fit_transform(X_train_set,y_train_set)\n",
    "predicted = lda.predict(X_test_set[features2])\n",
    "log_mse = mean_squared_error(y_test_set,predicted)\n",
    "log_rmse = np.sqrt(log_mse)\n",
    "print(\"The mse of lda is\",log_mse)\n",
    "print(\"The rmse of lda is\",log_rmse)\n",
    "\n",
    "#qda using sklearn\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train_set,y_train_set)\n",
    "predicted2 = qda.predict(X_test_set[features2])\n",
    "log_mse = mean_squared_error(y_test_set,predicted2)\n",
    "log_rmse = np.sqrt(log_mse)\n",
    "print(\"The mse of qda is\",log_mse)\n",
    "print(\"The rmse of qda is\",log_rmse)\n",
    "#plt.scatter(X_reduced_lda,y1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dowloading the data file and getting its description\n",
    "input_file = \"concrete_data.csv\"\n",
    "df3 = pd.read_csv(input_file)\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using log(x+1) transformation to scale all conditions except age and strength \n",
    "df3_condition_variables = ['comp_1','comp_2','comp_3','comp_4','comp_5','comp_6','comp_7']\n",
    "df3[df3_condition_variables] = np.log(df3[df3_condition_variables]+1)\n",
    "print(df3)\n",
    "df3.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using forward selection code to get the best model\n",
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#running the forward selection function \n",
    "model = forward_selected(df3,'strength')\n",
    "print(model.model.formula)\n",
    "# sl ~ rk + yr + 1\n",
    "print(model.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code hacked from hitters.csv\n",
    "\n",
    "y = df3.strength\n",
    "features = ['comp_1','comp_2','comp_3','comp_4','comp_5','comp_6','comp_7','age']\n",
    "X = df3[features]\n",
    "\n",
    "#best subset selection code \n",
    "def helperfunction(feature_set):\n",
    "    # Fit model on features and calculate RSS\n",
    "    model = sm.OLS(y,X[list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    RSS = ((regr.predict(X[list(feature_set)]) - y) ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS}\n",
    "\n",
    "def getBest(k):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(helperfunction(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model\n",
    "\n",
    "\n",
    "# This returns a `DataFrame` containing the best model that we generated, along with some extra information about the model. Now we want to call that function for each number of predictors $k$:\n",
    "models_best = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1,9):\n",
    "    models_best.loc[i] = getBest(i)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")\n",
    "\n",
    "\n",
    "# Now we have one big `DataFrame` that contains the best models we've generated along with their RSS:\n",
    "\n",
    "\n",
    "models_best\n",
    "\n",
    "\n",
    "# If we want to access the details of each model, no problem! We can get a full rundown of a single model using the `summary()` function:\n",
    "\n",
    "\n",
    "print(models_best.loc[2, \"model\"].summary())\n",
    "\n",
    "\n",
    "#r-square is 0.873, two predictors were selected: comp 1 and comp 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
